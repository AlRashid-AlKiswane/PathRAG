## üìÑ **Project Report: Paht-RAG Document Intelligence API wiht LLM (Ollama)**

### Prepared by: AlRashid AlKiswane

### For: Eng. Ghaith

### Date: July 28, 2025

---

### üîß **Technology Stack**

| Component         | Technology                            |
| ----------------- | ------------------------------------- |
| Backend API       | FastAPI                               |
| Vector Database   | MongoDB (with PyMongo)                |
| Embedding         | SentenceTransformer                   |
| Chunking          | Langchain Splitter                    |
| Graph Engine      | NetworkX (PathRAG)                    |
| LLM Backend       | Ollama + gemma3:1b                    |
| Logging           | Custom `logging` with tags            |
| Monitoring        | `psutil`, `nvidia-smi` (if available) |
| Frontend UI       | HTML, CSS, JavaScript                 |
| Visualization     | Plotly (semantic graph)               |
| Config Management | `.env` + Pydantic Settings            |

---

### üß† **High-Level Workflow**

#### 1. **Document Upload**

* API route: `/api/v1/upload`
* Uploaded files are renamed via `get_new_name()` for clarity and traceability.
* Files saved to local storage.

#### 2. **Chunking with Preprocessing**

* API route: `/api/v1/chunk`
* Uses **Langchain**'s splitter (with overlap).
* Preprocessed and split chunks are stored in the `chunks` collection in MongoDB.

#### 3. **Chunk Embedding**

* API route: `/api/v1/embed`
* Loads all chunks from `chunks` collection.
* Applies `all-MiniLM-L6-v2` SentenceTransformer embedding.
* Embeddings are stored in `embed_vector` collection.

#### 4. **Graph Construction: Path-RAG**

* API route: `/api/v1/build_graph`
* Uses embeddings to create a **semantic graph** with nodes (chunks) and edges (semantic similarity).
* Parameters like decay rate, similarity thresholds, and prune thresholds are configurable.
* Stores graph in a serialized `graph.pickle` file.
* On subsequent runs, loads from the pickle unless new data is added.

#### 5. **Chatbot with Path-Aware Retrieval**

* API route: `/api/v1/chatbot`
* Steps:

  * Validate `user_id` and check for existing queries (from `chatbot` collection).
  * If not cached, run top-k retrieval from PathRAG.
  * Score and prune semantic paths.
  * Generate a condensed prompt from the most relevant paths.
  * Call **Ollama model** to generate a response.
  * Store final query + response + paths in `chatbot` collection.

#### 6. **Ollama LLM Auto-Management**

* Module checks if Ollama server is running.
* If not:

  * Attempts `systemctl` start (fails gracefully if not registered).
  * Fallback to direct `ollama serve` process.
  * Pulls model if not available.
* Loads model `gemma3:1b` and verifies availability before usage.

#### 7. **System Monitoring**

* API route: `/api/v1/resource`
* Real-time monitoring of:

  * CPU (% usage)
  * Memory (% usage)
  * Disk space
  * GPU (if available)
* Detects and logs warnings (e.g. high RAM usage).

---

### üì¶ **MongoDB Collections**

| Collection     | Purpose                                       |
| -------------- | --------------------------------------------- |
| `chunks`       | Stores chunked text documents                 |
| `embed_vector` | Stores embeddings (chunk ID + vector)         |
| `chatbot`      | Stores user queries, LLM responses, and paths |

---

### üß™ **Caching Logic**

* Implemented on chatbot route.
* Checks MongoDB if the same `(user_id, query)` already exists.
* If found, returns the existing result to reduce LLM load and response time.

---

### üìä **Graph Metadata**

* Nodes: \~3000
* Edges: \~2.5M+
* Graph stored as: `/storge_graph/graph.pickle`
* Ensured no duplication on saving via unique IDs and hash checks.

---

### üìà **Logging System**

Each module logs to console and file with custom tags:

* `MAIN`
* `MONGO-ENGINE`
* `OLLAMA-MANEGER`
* `PATH-RAG`
* `CHATBOT-WORKFLOW`
* `RESOURCE-MONITOR`
* `DEPENDENTS`
* Levels: `INFO`, `DEBUG`, `WARNING`, `ERROR`

Example Logs:

```log
2025-07-28 16:13:42,718 - MONGO-ENGINE - INFO - Connected to local MongoDB at: mongodb://localhost:27017
2025-07-28 16:13:43,760 - OLLAMA-MANEGER - INFO - Model 'gemma3:1b' started successfully in background
2025-07-28 16:14:57,730 - CHATBOT-WORKFLOW - INFO - Retrieved and scored 325 semantic paths.
2025-07-28 16:27:30,969 - RESOURCE-MONITOR-CORE - WARNING - High memory usage detected: 95.50%
```

---

### üåê **Frontend UI**

* Built using **HTML**, **CSS**, **JavaScript**
* Interactive semantic graph (nodes + relationships) rendered via **Plotly**.
* User flow:

  * Upload ‚Üí Chunk ‚Üí Embed ‚Üí Build Graph ‚Üí Chatbot Interface ‚Üí View Graph

---

### ‚öôÔ∏è **Environment Configuration**

All critical values are stored in `.env` and loaded using `Pydantic`:

```env
MONGO_URI=mongodb://localhost:27017
DATABASE_NAME=PathRAG-MongoDB
OLLAMA_MODEL=gemma3:1b
EMBEDDING_MODEL=all-MiniLM-L6-v2
GRAPH_PICKLE_PATH=./storge_graph/graph.pickle
```

---

### ‚úÖ **System Highlights**

* Fully modular FastAPI backend
* Auto-booting Ollama and model pulling
* Full-text chunking, vector storage, and graph building
* Path-aware semantic reasoning using PathRAG
* Response caching and system monitoring
* Frontend UI + 3D graph visualization
* Clean code separation by responsibility
* High observability via loggers and performance metrics

---

